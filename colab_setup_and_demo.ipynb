{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ü§ñ VERL + LangGraph Multi-Agent Coding Framework - Colab Setup\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/multiminddev/coding-framework/blob/main/colab_setup_and_demo.ipynb)\n",
    "\n",
    "This notebook sets up and demonstrates the VERL + LangGraph Multi-Agent Coding Framework in Google Colab with HuggingFace models for local inference.\n",
    "\n",
    "## Features Demonstrated:\n",
    "- üîß **Code Generator Agent**: Creates code solutions from problem descriptions\n",
    "- üìù **Code Reviewer Agent**: Reviews code for quality, security, and performance\n",
    "- ‚ö° **Code Executor Agent**: Tests and validates code execution\n",
    "- üîÑ **LangGraph Orchestration**: Multi-agent workflow coordination\n",
    "- üß† **HuggingFace Models**: Local model inference without API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üöÄ Setup and Installation\n",
    "\n",
    "Let's start by setting up the environment and installing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive to save models and results\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories for our project\n",
    "import os\n",
    "os.makedirs('/content/drive/MyDrive/coding_framework', exist_ok=True)\n",
    "os.makedirs('/content/model_cache', exist_ok=True)\n",
    "os.makedirs('/content/data', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted and directories created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "system_info"
   },
   "outputs": [],
   "source": [
    "# Check system resources\n",
    "!nvidia-smi\n",
    "!free -h\n",
    "!df -h\n",
    "\n",
    "import torch\n",
    "print(f\"\\nüî• CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/multiminddev/coding-framework.git /content/coding-framework\n",
    "%cd /content/coding-framework\n",
    "\n",
    "print(\"‚úÖ Repository cloned successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install Colab-optimized dependencies\n",
    "!pip install -r requirements-colab.txt\n",
    "\n",
    "# Install the framework in development mode\n",
    "!pip install -e .\n",
    "\n",
    "print(\"‚úÖ Dependencies installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_environment"
   },
   "outputs": [],
   "source": [
    "# Set up environment variables for Colab\n",
    "import os\n",
    "os.environ['PYTHONPATH'] = '/content/coding-framework/src'\n",
    "os.environ['COLAB_MODE'] = 'true'\n",
    "os.environ['HF_HOME'] = '/content/model_cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/content/model_cache'\n",
    "\n",
    "# Optional: Set HuggingFace token if you want to access gated models\n",
    "# os.environ['HUGGINGFACE_HUB_TOKEN'] = 'your_token_here'\n",
    "\n",
    "print(\"‚úÖ Environment variables configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_selection"
   },
   "source": [
    "## üß† Model Selection for Colab\n",
    "\n",
    "Choose the appropriate model based on your Colab resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "select_model"
   },
   "outputs": [],
   "source": [
    "# Model options for different Colab tiers\n",
    "MODELS = {\n",
    "    \"lightweight\": {\n",
    "        \"name\": \"microsoft/DialoGPT-small\",\n",
    "        \"description\": \"Lightweight model, works on free Colab\",\n",
    "        \"memory\": \"~1GB\"\n",
    "    },\n",
    "    \"medium\": {\n",
    "        \"name\": \"microsoft/CodeGPT-small-py\", \n",
    "        \"description\": \"Code-focused model, good balance\",\n",
    "        \"memory\": \"~2GB\"\n",
    "    },\n",
    "    \"advanced\": {\n",
    "        \"name\": \"Salesforce/codegen-350M-multi\",\n",
    "        \"description\": \"Multi-language code generation\",\n",
    "        \"memory\": \"~3GB\"\n",
    "    },\n",
    "    \"powerful\": {\n",
    "        \"name\": \"bigcode/starcoder2-3b\",\n",
    "        \"description\": \"High-quality code generation (Colab Pro)\",\n",
    "        \"memory\": \"~6GB\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display model options\n",
    "print(\"Available models for Colab:\")\n",
    "for key, model in MODELS.items():\n",
    "    print(f\"\\n{key.upper()}:\")\n",
    "    print(f\"  Model: {model['name']}\")\n",
    "    print(f\"  Description: {model['description']}\")\n",
    "    print(f\"  Memory: {model['memory']}\")\n",
    "\n",
    "# Select model based on GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    if gpu_memory > 14:  # Colab Pro/Pro+\n",
    "        selected_model = MODELS[\"powerful\"]\n",
    "    elif gpu_memory > 10:  # Standard GPU\n",
    "        selected_model = MODELS[\"advanced\"]\n",
    "    else:\n",
    "        selected_model = MODELS[\"medium\"]\n",
    "else:\n",
    "    selected_model = MODELS[\"lightweight\"]\n",
    "\n",
    "print(f\"\\nüéØ Selected model: {selected_model['name']}\")\n",
    "print(f\"üìù Description: {selected_model['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "framework_setup"
   },
   "source": [
    "## ‚öôÔ∏è Framework Configuration\n",
    "\n",
    "Set up the framework with Colab-optimized configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_config"
   },
   "outputs": [],
   "source": [
    "# Create Colab-specific configuration\n",
    "from src.coding_framework.utils.config import Config, LLMConfig\n",
    "import yaml\n",
    "\n",
    "# Load base Colab config\n",
    "with open('config/colab_config.yaml', 'r') as f:\n",
    "    config_data = yaml.safe_load(f)\n",
    "\n",
    "# Update with selected model\n",
    "config_data['llm']['model'] = selected_model['name']\n",
    "\n",
    "# Save updated config\n",
    "with open('/content/colab_runtime_config.yaml', 'w') as f:\n",
    "    yaml.dump(config_data, f, default_flow_style=False)\n",
    "\n",
    "# Load configuration\n",
    "config = Config(**config_data)\n",
    "\n",
    "print(\"‚úÖ Configuration created for Colab\")\n",
    "print(f\"üß† Using model: {config.llm.model}\")\n",
    "print(f\"üîß Provider: {config.llm.provider}\")\n",
    "print(f\"üéõÔ∏è Max tokens: {config.llm.max_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "initialize_framework"
   },
   "outputs": [],
   "source": [
    "# Initialize the framework\n",
    "import asyncio\n",
    "from src.coding_framework.orchestration import CodingSupervisor\n",
    "from src.coding_framework.utils import setup_logging\n",
    "\n",
    "# Setup logging for Colab\n",
    "setup_logging(level=\"INFO\", verbose=True, format_type=\"text\")\n",
    "\n",
    "# Initialize supervisor\n",
    "supervisor = CodingSupervisor(config)\n",
    "\n",
    "print(\"üéØ Initializing framework components...\")\n",
    "print(\"‚ö†Ô∏è  This may take a few minutes to download and load the model...\")\n",
    "\n",
    "# Initialize in async context\n",
    "async def init_framework():\n",
    "    await supervisor.initialize()\n",
    "    return await supervisor.health_check()\n",
    "\n",
    "# Run initialization\n",
    "health_status = await init_framework()\n",
    "\n",
    "print(\"\\n‚úÖ Framework initialized successfully!\")\n",
    "print(f\"üè• System health: {health_status['system']['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "demo_section"
   },
   "source": [
    "## üéØ Demo: Multi-Agent Code Generation\n",
    "\n",
    "Let's demonstrate the framework with a complete coding workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "demo_simple_problem"
   },
   "outputs": [],
   "source": [
    "# Demo 1: Simple problem solving\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.syntax import Syntax\n",
    "\n",
    "console = Console()\n",
    "\n",
    "async def demo_simple_problem():\n",
    "    problem = \"Write a Python function to calculate the factorial of a number\"\n",
    "    \n",
    "    console.print(Panel.fit(\n",
    "        f\"[bold blue]Problem:[/bold blue] {problem}\",\n",
    "        border_style=\"blue\"\n",
    "    ))\n",
    "    \n",
    "    # Solve the problem\n",
    "    result = await supervisor.solve_problem(\n",
    "        problem,\n",
    "        context={\n",
    "            \"language\": \"python\",\n",
    "            \"style\": \"clean\",\n",
    "            \"include_tests\": False\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        # Display generated code\n",
    "        console.print(\"\\n[bold green]‚úÖ Generated Code:[/bold green]\")\n",
    "        syntax = Syntax(result[\"code\"], \"python\", theme=\"github-dark\")\n",
    "        console.print(syntax)\n",
    "        \n",
    "        # Display review\n",
    "        if result.get(\"review\"):\n",
    "            console.print(\"\\n[bold yellow]üìù Code Review:[/bold yellow]\")\n",
    "            console.print(result[\"review\"])\n",
    "        \n",
    "        # Display execution results\n",
    "        if result.get(\"execution\"):\n",
    "            console.print(\"\\n[bold cyan]‚ö° Execution Results:[/bold cyan]\")\n",
    "            console.print(result[\"execution\"])\n",
    "        \n",
    "        console.print(f\"\\n[dim]‚è±Ô∏è  Total time: {result.get('execution_time', 0):.2f}s[/dim]\")\n",
    "    else:\n",
    "        console.print(f\"[bold red]‚ùå Error:[/bold red] {result.get('error')}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run the demo\n",
    "simple_result = await demo_simple_problem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "demo_complex_problem"
   },
   "outputs": [],
   "source": [
    "# Demo 2: More complex problem with multiple iterations\n",
    "async def demo_complex_problem():\n",
    "    problem = \"\"\"Create a Python class that implements a simple calculator with the following features:\n",
    "    1. Basic operations (add, subtract, multiply, divide)\n",
    "    2. Memory functions (store, recall, clear)\n",
    "    3. Error handling for division by zero\n",
    "    4. Method chaining support\n",
    "    \"\"\"\n",
    "    \n",
    "    console.print(Panel.fit(\n",
    "        f\"[bold blue]Complex Problem:[/bold blue]\\n{problem}\",\n",
    "        border_style=\"blue\"\n",
    "    ))\n",
    "    \n",
    "    # Solve with enhanced context\n",
    "    result = await supervisor.solve_problem(\n",
    "        problem,\n",
    "        context={\n",
    "            \"language\": \"python\",\n",
    "            \"style\": \"clean\",\n",
    "            \"include_tests\": False,\n",
    "            \"max_iterations\": 3\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        console.print(\"\\n[bold green]‚úÖ Generated Calculator Class:[/bold green]\")\n",
    "        syntax = Syntax(result[\"code\"], \"python\", theme=\"github-dark\")\n",
    "        console.print(syntax)\n",
    "        \n",
    "        console.print(f\"\\n[bold magenta]üìä Metrics:[/bold magenta]\")\n",
    "        console.print(f\"‚Ä¢ Iterations: {result.get('iterations', 'N/A')}\")\n",
    "        console.print(f\"‚Ä¢ Review Score: {result.get('review_score', 'N/A')}/100\")\n",
    "        console.print(f\"‚Ä¢ Execution Success: {result.get('execution_success', 'N/A')}\")\n",
    "    else:\n",
    "        console.print(f\"[bold red]‚ùå Error:[/bold red] {result.get('error')}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run the complex demo\n",
    "complex_result = await demo_complex_problem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "demo_individual_agents"
   },
   "outputs": [],
   "source": [
    "# Demo 3: Individual agent testing\n",
    "async def test_individual_agents():\n",
    "    console.print(Panel.fit(\n",
    "        \"[bold purple]Testing Individual Agents[/bold purple]\",\n",
    "        border_style=\"purple\"\n",
    "    ))\n",
    "    \n",
    "    # Test Code Generator\n",
    "    console.print(\"\\n[bold]1. Testing Code Generator Agent:[/bold]\")\n",
    "    gen_result = await supervisor.generate_code(\n",
    "        \"Write a function to check if a number is prime\",\n",
    "        context={\"language\": \"python\"}\n",
    "    )\n",
    "    \n",
    "    if gen_result[\"success\"]:\n",
    "        console.print(\"[green]‚úÖ Generator working[/green]\")\n",
    "        print(f\"Generated: {len(gen_result['content'])} characters\")\n",
    "    else:\n",
    "        console.print(\"[red]‚ùå Generator failed[/red]\")\n",
    "    \n",
    "    # Test Code Reviewer\n",
    "    console.print(\"\\n[bold]2. Testing Code Reviewer Agent:[/bold]\")\n",
    "    sample_code = '''def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    return n * factorial(n-1)'''\n",
    "    \n",
    "    review_result = await supervisor.review_code(sample_code)\n",
    "    \n",
    "    if review_result[\"success\"]:\n",
    "        console.print(\"[green]‚úÖ Reviewer working[/green]\")\n",
    "        score = review_result.get(\"metadata\", {}).get(\"overall_score\", \"N/A\")\n",
    "        print(f\"Review score: {score}/100\")\n",
    "    else:\n",
    "        console.print(\"[red]‚ùå Reviewer failed[/red]\")\n",
    "    \n",
    "    # Test Code Executor\n",
    "    console.print(\"\\n[bold]3. Testing Code Executor Agent:[/bold]\")\n",
    "    simple_code = \"print('Hello from the executor!')\"\n",
    "    \n",
    "    exec_result = await supervisor.execute_code(\n",
    "        simple_code,\n",
    "        context={\"language\": \"python\"}\n",
    "    )\n",
    "    \n",
    "    if exec_result[\"success\"]:\n",
    "        console.print(\"[green]‚úÖ Executor working[/green]\")\n",
    "    else:\n",
    "        console.print(\"[red]‚ùå Executor failed[/red]\")\n",
    "        console.print(f\"Error: {exec_result.get('error')}\")\n",
    "\n",
    "# Test individual agents\n",
    "await test_individual_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "performance_section"
   },
   "source": [
    "## üìä Performance Monitoring\n",
    "\n",
    "Monitor system performance during execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "monitor_performance"
   },
   "outputs": [],
   "source": [
    "# Performance monitoring\n",
    "import psutil\n",
    "import GPUtil\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_system_stats():\n",
    "    \"\"\"Get current system statistics.\"\"\"\n",
    "    stats = {\n",
    "        'cpu_percent': psutil.cpu_percent(interval=1),\n",
    "        'memory_percent': psutil.virtual_memory().percent,\n",
    "        'disk_percent': psutil.disk_usage('/').percent\n",
    "    }\n",
    "    \n",
    "    # GPU stats if available\n",
    "    try:\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        if gpus:\n",
    "            stats['gpu_percent'] = gpus[0].load * 100\n",
    "            stats['gpu_memory_percent'] = (gpus[0].memoryUsed / gpus[0].memoryTotal) * 100\n",
    "    except:\n",
    "        stats['gpu_percent'] = 0\n",
    "        stats['gpu_memory_percent'] = 0\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Get current performance metrics\n",
    "stats = get_system_stats()\n",
    "performance_metrics = supervisor.get_performance_metrics()\n",
    "\n",
    "console.print(Panel.fit(\n",
    "    f\"\"\"[bold cyan]System Performance[/bold cyan]\n",
    "\n",
    "[bold]Resource Usage:[/bold]\n",
    "üî• CPU: {stats['cpu_percent']:.1f}%\n",
    "üß† RAM: {stats['memory_percent']:.1f}%\n",
    "üíæ Disk: {stats['disk_percent']:.1f}%\n",
    "üéÆ GPU: {stats['gpu_percent']:.1f}%\n",
    "üìä GPU Memory: {stats['gpu_memory_percent']:.1f}%\n",
    "\n",
    "[bold]Framework Metrics:[/bold]\n",
    "‚úÖ Problems Solved: {performance_metrics.get('total_problems_solved', 0)}\n",
    "üéØ Success Rate: {(performance_metrics.get('successful_solutions', 0) / max(1, performance_metrics.get('total_problems_solved', 1)) * 100):.1f}%\n",
    "‚è±Ô∏è  Avg Response Time: {performance_metrics.get('avg_execution_time', 0):.2f}s\n",
    "üìù Avg Review Score: {performance_metrics.get('avg_review_score', 0):.1f}/100\n",
    "\"\"\",\n",
    "    border_style=\"cyan\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "testing_section"
   },
   "source": [
    "## üß™ Running Tests\n",
    "\n",
    "Let's run some basic tests to ensure everything works correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_basic_tests"
   },
   "outputs": [],
   "source": [
    "# Run basic framework tests\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "console.print(Panel.fit(\n",
    "    \"[bold green]Running Framework Tests[/bold green]\",\n",
    "    border_style=\"green\"\n",
    "))\n",
    "\n",
    "# Test configuration loading\n",
    "print(\"1. Testing configuration loading...\")\n",
    "try:\n",
    "    from src.coding_framework.utils.config import load_config\n",
    "    test_config = load_config('/content/colab_runtime_config.yaml')\n",
    "    assert test_config.llm.provider == \"huggingface\"\n",
    "    print(\"   ‚úÖ Configuration test passed\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Configuration test failed: {e}\")\n",
    "\n",
    "# Test LLM interface\n",
    "print(\"\\n2. Testing LLM interface...\")\n",
    "try:\n",
    "    from src.coding_framework.utils.llm_interface import LLMInterface\n",
    "    llm_interface = LLMInterface(test_config.llm)\n",
    "    health = await llm_interface.health_check()\n",
    "    print(f\"   ‚úÖ LLM interface test passed: {health['status']}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå LLM interface test failed: {e}\")\n",
    "\n",
    "# Test agent initialization\n",
    "print(\"\\n3. Testing agent initialization...\")\n",
    "try:\n",
    "    health_status = await supervisor.health_check()\n",
    "    healthy_agents = sum(1 for agent, status in health_status.items() \n",
    "                        if isinstance(status, dict) and status.get('status') == 'healthy')\n",
    "    print(f\"   ‚úÖ Agent initialization test passed: {healthy_agents} healthy agents\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Agent initialization test failed: {e}\")\n",
    "\n",
    "# Test basic workflow\n",
    "print(\"\\n4. Testing basic workflow...\")\n",
    "try:\n",
    "    simple_test = await supervisor.solve_problem(\n",
    "        \"Write a function that returns 'Hello World'\",\n",
    "        context={\"language\": \"python\", \"max_iterations\": 1}\n",
    "    )\n",
    "    if simple_test[\"success\"]:\n",
    "        print(\"   ‚úÖ Basic workflow test passed\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Basic workflow test completed with issues: {simple_test.get('error')}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Basic workflow test failed: {e}\")\n",
    "\n",
    "print(\"\\nüéâ Test suite completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_unit_tests"
   },
   "outputs": [],
   "source": [
    "# Run selected unit tests (modified for Colab)\n",
    "print(\"Running unit tests (Colab-compatible subset)...\")\n",
    "\n",
    "# Test imports\n",
    "try:\n",
    "    from src.coding_framework import (\n",
    "        CodeGeneratorAgent,\n",
    "        CodeReviewerAgent,\n",
    "        CodeExecutorAgent,\n",
    "        CodingSupervisor\n",
    "    )\n",
    "    print(\"‚úÖ All core imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "\n",
    "# Test agent type properties\n",
    "try:\n",
    "    generator = supervisor.agents[\"generator\"]\n",
    "    reviewer = supervisor.agents[\"reviewer\"]\n",
    "    executor = supervisor.agents[\"executor\"]\n",
    "    \n",
    "    assert generator.agent_type == \"code_generator\"\n",
    "    assert reviewer.agent_type == \"code_reviewer\"\n",
    "    assert executor.agent_type == \"code_executor\"\n",
    "    \n",
    "    print(\"‚úÖ Agent type tests passed\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Agent type test failed: {e}\")\n",
    "\n",
    "# Test configuration validation\n",
    "try:\n",
    "    from src.coding_framework.utils.config import validate_config\n",
    "    issues = validate_config(test_config)\n",
    "    if not issues:\n",
    "        print(\"‚úÖ Configuration validation passed\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Configuration has issues: {issues}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Configuration validation failed: {e}\")\n",
    "\n",
    "print(\"\\nüß™ Unit tests completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save_results"
   },
   "source": [
    "## üíæ Save Results and Models\n",
    "\n",
    "Save your work to Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_to_drive"
   },
   "outputs": [],
   "source": [
    "# Save results and configuration to Drive\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Prepare results summary\n",
    "results_summary = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"model_used\": selected_model[\"name\"],\n",
    "    \"system_info\": {\n",
    "        \"gpu_available\": torch.cuda.is_available(),\n",
    "        \"gpu_name\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\",\n",
    "        \"colab_type\": \"GPU\" if torch.cuda.is_available() else \"CPU\"\n",
    "    },\n",
    "    \"performance_metrics\": supervisor.get_performance_metrics(),\n",
    "    \"demo_results\": {\n",
    "        \"simple_problem\": {\n",
    "            \"success\": simple_result.get(\"success\", False),\n",
    "            \"execution_time\": simple_result.get(\"execution_time\", 0)\n",
    "        },\n",
    "        \"complex_problem\": {\n",
    "            \"success\": complex_result.get(\"success\", False),\n",
    "            \"execution_time\": complex_result.get(\"execution_time\", 0),\n",
    "            \"iterations\": complex_result.get(\"iterations\", 0)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to Drive\n",
    "output_dir = '/content/drive/MyDrive/coding_framework/colab_session'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save results\n",
    "with open(f'{output_dir}/results_{timestamp}.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "# Save configuration\n",
    "with open(f'{output_dir}/config_{timestamp}.yaml', 'w') as f:\n",
    "    yaml.dump(config.dict(), f, default_flow_style=False)\n",
    "\n",
    "# Save demo code examples\n",
    "if simple_result.get(\"success\"):\n",
    "    with open(f'{output_dir}/generated_code_{timestamp}.py', 'w') as f:\n",
    "        f.write(f\"# Simple Problem Solution\\n\")\n",
    "        f.write(f\"# Generated at: {datetime.now()}\\n\")\n",
    "        f.write(f\"# Model: {selected_model['name']}\\n\\n\")\n",
    "        f.write(simple_result[\"code\"])\n",
    "        \n",
    "        if complex_result.get(\"success\"):\n",
    "            f.write(f\"\\n\\n# Complex Problem Solution\\n\")\n",
    "            f.write(complex_result[\"code\"])\n",
    "\n",
    "console.print(Panel.fit(\n",
    "    f\"\"\"[bold green]‚úÖ Session Saved Successfully![/bold green]\n",
    "\n",
    "[bold]Saved Files:[/bold]\n",
    "üìä Results: results_{timestamp}.json\n",
    "‚öôÔ∏è  Config: config_{timestamp}.yaml\n",
    "üêç Code: generated_code_{timestamp}.py\n",
    "\n",
    "[bold]Location:[/bold] {output_dir}\n",
    "\n",
    "[dim]You can access these files from your Google Drive.[/dim]\n",
    "\"\"\",\n",
    "    border_style=\"green\"\n",
    "))\n",
    "\n",
    "print(f\"\\nüéØ Total problems solved: {supervisor.get_performance_metrics().get('total_problems_solved', 0)}\")\n",
    "print(f\"‚è±Ô∏è  Average response time: {supervisor.get_performance_metrics().get('avg_execution_time', 0):.2f}s\")\n",
    "print(f\"üìù Average review score: {supervisor.get_performance_metrics().get('avg_review_score', 0):.1f}/100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "Now that you have the framework running in Colab, here are some things you can try:\n",
    "\n",
    "### üéØ **Experiment with Different Problems**\n",
    "```python\n",
    "# Try more complex problems\n",
    "problems = [\n",
    "    \"Implement a binary search tree with insert, delete, and search operations\",\n",
    "    \"Create a web scraper that respects robots.txt\",\n",
    "    \"Write a function to find the longest common subsequence\",\n",
    "    \"Implement a simple neural network from scratch\"\n",
    "]\n",
    "\n",
    "for problem in problems:\n",
    "    result = await supervisor.solve_problem(problem, context={\"language\": \"python\"})\n",
    "    # Process results...\n",
    "```\n",
    "\n",
    "### üîß **Customize Configuration**\n",
    "- Modify `config/colab_config.yaml` for different settings\n",
    "- Try different HuggingFace models\n",
    "- Adjust workflow parameters\n",
    "\n",
    "### üß† **Try Different Models**\n",
    "- Code-specific models: `bigcode/starcoder2-3b`\n",
    "- Multi-language models: `Salesforce/codegen-350M-multi`\n",
    "- Instruction-tuned models: `microsoft/DialoGPT-medium`\n",
    "\n",
    "### üìä **Monitor Performance**\n",
    "- Use the performance monitoring cells above\n",
    "- Track memory usage with different model sizes\n",
    "- Compare generation quality across models\n",
    "\n",
    "### üöÄ **Scale Up (Colab Pro)**\n",
    "- Use larger models with more GPU memory\n",
    "- Enable VERL training (coming soon)\n",
    "- Process multiple problems in parallel\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- **Framework Documentation**: [GitHub Repository](https://github.com/multiminddev/coding-framework)\n",
    "- **HuggingFace Models**: [Hub](https://huggingface.co/models?pipeline_tag=text-generation)\n",
    "- **LangGraph Documentation**: [LangChain Docs](https://langchain-ai.github.io/langgraph/)\n",
    "- **VERL Framework**: [VERL GitHub](https://github.com/volcengine/verl)\n",
    "\n",
    "## üêõ Troubleshooting\n",
    "\n",
    "If you encounter issues:\n",
    "\n",
    "1. **Memory Issues**: Use smaller models or restart runtime\n",
    "2. **Model Loading**: Check internet connection and HuggingFace status\n",
    "3. **CUDA Errors**: Restart runtime and ensure GPU is enabled\n",
    "4. **Import Errors**: Reinstall dependencies with `!pip install -r requirements-colab.txt`\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations!** You've successfully set up and tested the VERL + LangGraph Multi-Agent Coding Framework in Google Colab with HuggingFace models! üöÄ"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}